# ===============================================================================
# Research Paper Answer Bot - Simple Deployment Version
# Created by: Daniel Ojeda Rosales
# ===============================================================================

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import time
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
import uuid
import re

# ============= MINIMAL RAG COMPONENTS =============
# Since your full RAG system is complex, we'll use a simplified version that works



# ============= STREAMLIT APP =============

def main():
    # Page config
    st.set_page_config(
        page_title="ğŸ¤– Research Paper Answer Bot | Daniel Ojeda Rosales",
        page_icon="ğŸ§ ",
        layout="wide"
    )

    # Custom CSS for dark theme
    st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        color: #00d4ff;
        text-align: center;
        margin-bottom: 1rem;
    }
    .creator-name {
        font-size: 1.2rem;
        color: #ff6b9d;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .user-message {
        background-color: #667eea;
        color: white;
    }
    .bot-message {
        background-color: #11998e;
        color: white;
    }
    </style>
    """, unsafe_allow_html=True)

    # Header
    st.markdown("""
    <div class="main-header">ğŸ¤– Research Paper Answer Bot</div>
    <div class="creator-name">âœ¨ Created by Daniel Ojeda Rosales âœ¨</div>
    """, unsafe_allow_html=True)

    # Initialize session state
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    # Sidebar
    with st.sidebar:
        st.markdown("### ğŸ¯ About")
        st.markdown("""
        This is an AI-powered research assistant that can answer questions about:
        - ğŸ¤– Transformer architectures
        - ğŸ§  BERT and GPT models
        - ğŸ“– Deep learning research
        - ğŸ” Natural language processing
        """)

        st.markdown("### âš™ï¸ Settings")
        response_style = st.selectbox("Response Style", ["Academic", "Professional", "Casual"])
        show_sources = st.checkbox("Show Sources", value=True)

        if st.button("ğŸ—‘ï¸ Clear Chat"):
            st.session_state.messages = []
            st.rerun()

    # Main chat interface
    st.markdown("## ğŸ’¬ Ask me about AI/ML research papers!")

    # Display chat messages
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f"""
            <div class="chat-message user-message">
                <strong>ğŸ‘¤ You:</strong> {message["content"]}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="chat-message bot-message">
                <strong>ğŸ¤– Bot:</strong> {message["content"]}
            </div>
            """, unsafe_allow_html=True)

            # Show sources if enabled
            if show_sources and "sources" in message:
                st.markdown("**ğŸ“š Sources:**")
                for i, source in enumerate(message["sources"][:3], 1):
                    st.markdown(f"   {i}. {source['filename']} (Page {source['page']}) - Score: {source['score']:.2f}")

    # Chat input
    user_input = st.text_input("ğŸ’­ Type your question here...", key="user_input")

    col1, col2 = st.columns([1, 4])
    with col1:
        send_button = st.button("ğŸš€ Send", use_container_width=True)

    if send_button and user_input:
        # Add user message
        st.session_state.messages.append({"role": "user", "content": user_input})

        # Get RAG response
        with st.spinner("ğŸ¤” Thinking..."):
            rag_system = load_rag_system()
            response = rag_system.query(user_input)

            # Add bot message
            bot_message = {
                "role": "assistant",
                "content": response.answer,
                "sources": response.sources
            }
            st.session_state.messages.append(bot_message)

        st.rerun()

    # Sample questions
    if not st.session_state.messages:
        st.markdown("### ğŸ’¡ Try asking:")
        sample_questions = [
            "What is the transformer architecture?",
            "How does BERT work?",
            "Explain attention mechanisms",
            "What are the latest developments in LLMs?"
        ]

        cols = st.columns(2)
        for i, question in enumerate(sample_questions):
            with cols[i % 2]:
                if st.button(f"ğŸ’­ {question}", key=f"sample_{i}"):
                    st.session_state.messages.append({"role": "user", "content": question})

                    # Get response
                    rag_system = load_rag_system()
                    response = rag_system.query(question)

                    bot_message = {
                        "role": "assistant",
                        "content": response.answer,
                        "sources": response.sources
                    }
                    st.session_state.messages.append(bot_message)
                    st.rerun()

    # Footer
    st.markdown("---")
    st.markdown("ğŸ¤– **Research Paper Answer Bot** - Powered by AI | Created by Daniel Ojeda Rosales")

if __name__ == "__main__":
    main()
